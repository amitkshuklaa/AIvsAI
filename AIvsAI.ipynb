{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-09T22:50:51.699035Z","iopub.execute_input":"2024-04-09T22:50:51.699379Z","iopub.status.idle":"2024-04-09T22:50:52.773937Z","shell.execute_reply.started":"2024-04-09T22:50:51.699351Z","shell.execute_reply":"2024-04-09T22:50:52.772847Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install openai","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:51:09.162616Z","iopub.execute_input":"2024-04-09T22:51:09.163669Z","iopub.status.idle":"2024-04-09T22:51:22.559629Z","shell.execute_reply.started":"2024-04-09T22:51:09.163629Z","shell.execute_reply":"2024-04-09T22:51:22.558304Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-1.16.2-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\nDownloading openai-1.16.2-py3-none-any.whl (267 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: openai\nSuccessfully installed openai-1.16.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import openai\n# Set your OpenAI GPT API keys\njournalist_api_key = '' # put your API key here from chatgpt 1 instance\nai_expert_api_key = '' # put your API key here from chatgpt 2 instance\n","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:51:28.261857Z","iopub.execute_input":"2024-04-09T22:51:28.262343Z","iopub.status.idle":"2024-04-09T22:51:28.995350Z","shell.execute_reply.started":"2024-04-09T22:51:28.262297Z","shell.execute_reply":"2024-04-09T22:51:28.994213Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def journalist_chat(prompt):\n    openai.api_key = journalist_api_key\n    return openai.Completion.create(\n        engine='text-davinci-003',\n        prompt=prompt,\n        max_tokens=150\n    )['choices'][0]['text'].strip()\n\n# Set up the AI expert ChatGPT instance\ndef ai_expert_chat(prompt):\n    openai.api_key = ai_expert_api_key\n    return openai.Completion.create(\n        engine='text-davinci-003',\n        prompt=prompt,\n        max_tokens=150\n    )['choices'][0]['text'].strip()","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:51:31.506214Z","iopub.execute_input":"2024-04-09T22:51:31.506595Z","iopub.status.idle":"2024-04-09T22:51:31.514084Z","shell.execute_reply.started":"2024-04-09T22:51:31.506560Z","shell.execute_reply":"2024-04-09T22:51:31.512642Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:51:36.514449Z","iopub.execute_input":"2024-04-09T22:51:36.514972Z","iopub.status.idle":"2024-04-09T22:51:36.521346Z","shell.execute_reply.started":"2024-04-09T22:51:36.514925Z","shell.execute_reply":"2024-04-09T22:51:36.520069Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def main():\n    journalist_prompt = \"You are a journalist writing an article about AI. Interview an AI expert asking about developments and advancements in the field of artificial intelligence? Once the AI expert respond, ask further questions based on the response\"\n    print(\"\\nJournalist's Question:\", journalist_prompt)\n\n    max_iterations = 3\n    journalist_conversation = \"\"\n    ai_expert_conversation = \"\"\n\n    for iteration in range(1, max_iterations + 1):\n\n        prompt = journalist_prompt + f\"\\n\\nJournalist:\"\n        journalist_question = journalist_chat(prompt)\n        print(\"\\nJournalist's Question:\", journalist_question)\n        time.sleep(20)\n        journalist_conversation += f\"Journalist: {journalist_question}\\n\"  \n\n        prompt = journalist_prompt + f\"\\n\\nJournalist: {journalist_question}\\nAI Expert:\"\n        ai_expert_answer = ai_expert_chat(prompt)\n\n         \n     \n        ai_expert_conversation += f\"AI Expert: {ai_expert_answer}\\n\"\n        \n        print(f\"\\nIteration {iteration} - AI Expert:\", ai_expert_answer)\n        time.sleep(20)\n        \n\n\n    conclusive_summary_prompt = journalist_prompt + f\"\\n\\n{journalist_conversation}{ai_expert_conversation}Journalist: Provide a conclusive summary.\"\n    conclusive_summary = journalist_chat(conclusive_summary_prompt)\n\n\n    print(\"\\nConclusive Summary:\")\n    print(conclusive_summary)\n\n    #summary_prompt = journalist_prompt + f\"\\n\\nJournalist: Summarize the key points discussed.\"\n    #summary = journalist_chat(summary_prompt)\n\n\n    #print(\"\\nJournalist's Summary:\")\n    #print(summary)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:51:38.485645Z","iopub.execute_input":"2024-04-09T22:51:38.486878Z","iopub.status.idle":"2024-04-09T22:51:38.494185Z","shell.execute_reply.started":"2024-04-09T22:51:38.486834Z","shell.execute_reply":"2024-04-09T22:51:38.493429Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def main():\n    journalist_prompt = \"You are a journalist writing an article about P vs NP Problem. Interview an Maths expert asking about developments and advancements in the field of P vs NP problem? Once the Math expert respond, ask further questions based on the response\"\n    print(\"\\nJournalist's Question:\", journalist_prompt)\n\n    max_iterations = 3\n    journalist_conversation = \"\"\n    ai_expert_conversation = \"\"\n\n    for iteration in range(1, max_iterations + 1):\n\n        prompt = journalist_prompt + f\"\\n\\nJournalist:\"\n        journalist_question = journalist_chat(prompt)\n        print(\"\\nJournalist's Question:\", journalist_question)\n        time.sleep(20)\n        journalist_conversation += f\"Journalist: {journalist_question}\\n\"  \n\n        prompt = journalist_prompt + f\"\\n\\nJournalist: {journalist_question}\\nAI Expert:\"\n        ai_expert_answer = ai_expert_chat(prompt)\n\n         \n     \n        ai_expert_conversation += f\"AI Expert: {ai_expert_answer}\\n\"\n        \n        print(f\"\\nIteration {iteration} - AI Expert:\", ai_expert_answer)\n        time.sleep(20)\n        \n\n\n    conclusive_summary_prompt = journalist_prompt + f\"\\n\\n{journalist_conversation}{ai_expert_conversation}Journalist: Provide a conclusive summary.\"\n    conclusive_summary = journalist_chat(conclusive_summary_prompt)\n\n\n    print(\"\\nConclusive Summary:\")\n    print(conclusive_summary)\n\n    #summary_prompt = journalist_prompt + f\"\\n\\nJournalist: Summarize the key points discussed.\"\n    #summary = journalist_chat(summary_prompt)\n\n\n    #print(\"\\nJournalist's Summary:\")\n    #print(summary)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:51:46.544701Z","iopub.execute_input":"2024-04-09T22:51:46.545758Z","iopub.status.idle":"2024-04-09T22:51:46.553410Z","shell.execute_reply.started":"2024-04-09T22:51:46.545722Z","shell.execute_reply":"2024-04-09T22:51:46.552310Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:51:49.301872Z","iopub.execute_input":"2024-04-09T22:51:49.302708Z","iopub.status.idle":"2024-04-09T22:51:49.771202Z","shell.execute_reply.started":"2024-04-09T22:51:49.302662Z","shell.execute_reply":"2024-04-09T22:51:49.769770Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\nJournalist's Question: You are a journalist writing an article about P vs NP Problem. Interview an Maths expert asking about developments and advancements in the field of P vs NP problem? Once the Math expert respond, ask further questions based on the response\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[7], line 12\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_iterations \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     11\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m journalist_prompt \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mJournalist:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m     journalist_question \u001b[38;5;241m=\u001b[39m \u001b[43mjournalist_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mJournalist\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Question:\u001b[39m\u001b[38;5;124m\"\u001b[39m, journalist_question)\n\u001b[1;32m     14\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m20\u001b[39m)\n","Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mjournalist_chat\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjournalist_chat\u001b[39m(prompt):\n\u001b[1;32m      2\u001b[0m     openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m journalist_api_key\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext-davinci-003\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n","\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"],"ename":"APIRemovedInV1","evalue":"\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n","output_type":"error"}]},{"cell_type":"code","source":"journalist_chat(\"you are a journalist curious about the ML and AI. And now you will engage in the dialouge with the AI expert. You will start by asking what is the advancement in AI and after the Expert response, Wait for his response. You dont have to pretend to be AI Expert\")","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:51:56.526890Z","iopub.execute_input":"2024-04-09T22:51:56.527240Z","iopub.status.idle":"2024-04-09T22:51:56.569329Z","shell.execute_reply.started":"2024-04-09T22:51:56.527204Z","shell.execute_reply":"2024-04-09T22:51:56.568047Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjournalist_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myou are a journalist curious about the ML and AI. And now you will engage in the dialouge with the AI expert. You will start by asking what is the advancement in AI and after the Expert response, Wait for his response. You dont have to pretend to be AI Expert\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mjournalist_chat\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjournalist_chat\u001b[39m(prompt):\n\u001b[1;32m      2\u001b[0m     openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m journalist_api_key\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext-davinci-003\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n","\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"],"ename":"APIRemovedInV1","evalue":"\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n","output_type":"error"}]}]}